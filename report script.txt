
Rozdział 1. Usuwanie wartości odstających!

Zdecydowaliśmy się dla poprawienia skuteczności naszej analizy wyrzucić skrajne wartości z naszego zbioru danych. Konkretnie 2% najdroższych mieszkań oraz głównie dla zachowania balansu 2% najtańszych. Zbiór przedstawiajacy ceny mieszkań z naszego zbioru danych przedstawia wykres poniżej. Możemy na nim zaobserwować, że co najmniej kilka/kilkadziesiąt wartości zdecydowanie odstaje od pozostały. Z tego powodu postanowiliśmy nie uwzględniać ich w naszej analizie.

<odstajace1>

Usunięcie wartości odstających.
<odstajace2>

Różnice między zbiorami możemy zaobserwować na poniższych wykresach.

<Odstajace3>  <odstajace4>


Rozdział 2. OneHotEncoding oraz rozdzielanie danych!

Do poprawnego funkcjonowania modele uczenia maszynowego wymagają danych zapisanych w formie liczbowym(int, float, etc.) dlatego też zmienne zapisane w naszym zbiorze danych jako napisy(string) zostały zamienione na liczbowe za pomocą funkcji z pakietu pandas o nazwie get_dummies.

<podzial1>

Dane po odpowiedniej zmianie typu muszą zostać rozdzialone na odpowiednie zbiory. W pierwsze kolejności zostają one przypisane do zmiennych y oraz X, gdzie y jest etykietą(Ceną mieszkania) tzn wartością, którą ma nasz model przewidywać. Natomiast X jest wszystkim innym czyli zmiennymi na podstawie, których nasz przyszły model ma przewidzieć cene mieszkania. Kolejnym krokiem jest rozdzielenie powstałych w ten sposób zbiorów na treningowe oraz testowe. Zbiory treningowe X_train oraz y_train posłużą do uczenia modeli uczenia maszynowego, natomiast zbiory testowe X_test oraz y_test do sprawdzania wyników naszego modelu. Cały podział odbywa się za pomocą funkcji train_test_split z pakietu sklearn. Funkcja przyjmuje rozdzielone zmienne X,y oraz parametry takie jak test_size odpowiadajacy za rozmiar zbioru testowego (w naszym przypadku 20%) oraz random_state jest swego rodzajem ziarnem służącym do wyboru, które wiesze mają trafić do zbioru testowego, a które do uczącego. Random_state przyjmuje liczbe całkowitą jako wartość ziarna według, której konkretne wiersze trawiaja do danego podzbioru test lub train.


Rozdział 3. Walidacja krzyżowa w celu sprawdzenia możliwości modeli uczenia maszynowego.
Wyjaśnienie???



Za pomocą walidacji krzyżowej przetesowaliśmy takie modele jak Support Vector Machine Regressor, Linear Regression, KNN Regressor, Decision Tree Regresor oraz Random Forest Regressor. Walidacja krzyżowa daje bardziej miarodajne wyniki niż zwykłe testowanie modeli, ponieważ jako zbiór treningowy wykorzystuje wszystkie dane. W naszym przypadku wykorzystaliśmy podział cv = 10, co oznacza że każdy zbiór został podzielony na 10 części. Nastepnie dany model uczył się na 9 częściach oraz sprawdzany na tej ostatniej nie użytej do nauki, wynik uzyskany został zapisany, a cały proces został powtórzony jeszcze 9 razy za każdym razem ze zmianą części użytej do sprawdzenia. Po 10 takich iteracjach została wyciągnięta średnia jak wynik całego procesu.

DLaczego Walidacja krzyżowa?

Walidacja krzyżowa (cross-validation) jest lepsza od zwykłego testowania modeli z kilku powodów:

Lepsze wykorzystanie danych: Walidacja krzyżowa pozwala na bardziej efektywne wykorzystanie dostępnych danych. Zamiast podzielić zestaw danych na jedną próbkę testową i treningową, walidacja krzyżowa dzieli je na kilka podzbiorów, z których jeden jest używany jako zbiór testowy, a pozostałe jako zbiory treningowe. Dzięki temu każda próbka danych jest wykorzystywana zarówno do treningu, jak i do testowania modelu, co prowadzi do bardziej wiarygodnych wyników.

Wiarygodniejsza ocena modelu: Walidacja krzyżowa zapewnia bardziej wiarygodną ocenę jakości modelu. Podczas zwykłego testowania, wynik może być uzależniony od przypadkowego podziału danych na zbiory testowe i treningowe. W przypadku walidacji krzyżowej, wynik jest uśredniany z kilku prób, gdzie każda próba używa innego podziału danych. Pozwala to na bardziej obiektywne oszacowanie skuteczności modelu.

Lepsze wykrywanie przeuczenia (overfittingu): Walidacja krzyżowa jest skuteczniejsza w wykrywaniu przeuczenia modelu. Przeuczenie występuje, gdy model jest zbyt mocno dopasowany do danych treningowych i słabo generalizuje na nowe dane. Przy użyciu walidacji krzyżowej można wykryć ten problem poprzez porównanie wyników na różnych podzbiorach danych. Jeśli model jest przeuczony, to wyniki na zbiorze testowym będą gorsze niż na zbiorze treningowym.

Lepszy podział danych treningowych i testowych: Walidacja krzyżowa pozwala na lepszy podział danych treningowych i testowych. W zwykłym testowaniu często zdarza się, że niektóre ważne wzorce mogą być pomijane przez przypadek, gdy zostaną one umieszczone w zbiorze testowym. Walidacja krzyżowa pozwala na uwzględnienie wszystkich próbek danych zarówno w zbiorze treningowym, jak i testowym w różnych kombinacjach, co pozwala na bardziej kompleksową ocenę modelu.

Lepsza reprezentatywność wyników: Walidacja krzyżowa pozwala na uzyskanie bardziej reprezentatywnych wyników. Dzięki uśrednianiu wyników z wielu prób, możemy uzyskać bardziej stabilne i wiarygodne oszacowanie skuteczności modelu. Wyniki z jednej próby mogą być podatne na losowe fluktuacje, ale uśrednione wyniki z wielu prób są bardziej niezawodne.

Wyniki walidacji krzyżowej

Wartym oddnotowania jest fakt że modele użyte przez na w teście walidacji krzyżowej był testowane bez jakichkoliwek zmian hyperparametrów. Walidacja krzyżowa pokazała, które modele najbardziej nadają się do dalszego rozwoj. Są to Ridge, KNeighborsRegressor, DecisionTreeRegressor oraz RandomForestRegressor, odrzuciliśmy dwa modele liniowe takie jak SVR oraz LinearRegression. Nie oznacza to jedna że modele liniowe nie sprawdziły się w naszym teście, ponieważ doskonale wypadł model będącym usprawnioną regresją liniową czyli Ridge Regression. 

<crossvalidation>


Testowanie modeli przewidujących ceny mieszkań.

W celu porównania modeli uczenia maszynowego stworzona zostałą funkcja "ml", przyjmująca argumenty takie jak:
df - ramka danych potrzebnych do nauki modelu
model - instancja modelu który zostanie użyty
grid - zmienna która decyduje czy użyć GridSearchCV sprawdzającej każdą kombinacje zadanych parametrów w kolejnym argumencie grid_params
grid_params domyślnie przyjmująca zero służy głównie do przechowywania słownika potrzebnego funkcji GridSearchCV do znalezienia odpowiedniej kombinacji parametrów modelu.

Funkcja na początku dzieli lokalnie zbiór danych na podzbiory za pomocą train_test_split, następnie sprawdza czy użytkownik chce użyć GridSearchCV czy też nie za pomocą zmiennej Grid, która z koleji przyjmuje wartości True lub False. W dalszej częsci model uczy się na zbiorach treningowych, później przywiduje wynik na podstawie zbioru testowego. Żeby w późniejszej części prównać go z prawidłowymi wynikami za pomocą takcih metryk jak MAE, RMSE oraz R2 Score. Wyniki są również wyświetlane na wykresie, który demonstruje jak bardzo predykcje modelu odbiegają od prawidłowych wartości. Na sam koniec jeśli użytkownik wybrał, że chce skożystać z GridSearchCV wyświetlona zostaje najlepsza kombinacja parametrów. W dalszej części zaprezentowane zostanie działanie funkcji w praktyce.
########################################################################################################################################################################################################
Metryki oceny modelu.

MAE (Mean Absolute Error) i RMSE (Root Mean Squared Error) to popularne metryki używane w problemach regresji do oceny jakości predykcji modelu.

MAE mierzy średnią wartość bezwzględną błędów predykcji modelu, czyli średnią różnicę pomiędzy wartością rzeczywistą a wartością przewidywaną. MAE jest łatwy do interpretacji i nie wrażliwy na wartości odstające.

RMSE, podobnie jak MAE, mierzy błędy predykcji, ale jest to średnia kwadratowa różnica pomiędzy wartością rzeczywistą a wartością przewidywaną. Ponieważ RMSE bierze pod uwagę kwadrat błędów, to większe błędy są bardziej karane niż w przypadku MAE. RMSE jest często stosowany, gdy chcemy zwrócić uwagę na duże błędy predykcji.

R2 Score (lub R-squared) to metryka, która mierzy dopasowanie modelu do danych. R2 Score jest liczbą z zakresu od 0 do 1, gdzie wartość 1 oznacza idealne dopasowanie modelu do danych, a wartość 0 oznacza, że model nie wyjaśnia zmienności danych w ogóle. R2 Score wyraża proporcję zmienności danych, która jest wyjaśniona przez model. W praktyce, R2 Score jest używany jako miara wydajności modelu, która pokazuje, jak dobrze model przewiduje zmienność danych. Wartości R2 Score powyżej 0,7 zazwyczaj uważane są za dobre dopasowanie modelu.
########################################################################################################################################################################################################
<funkcjatestujaca>

Ridge Regression

Ridge Regression jest rozserzeniem regresji liniowej wprowadzającym dodatkową regularyzajce L2. Dzięki regularyzacji L2, Ridge Regression daje elastyczność w dostosowywaniu modelu do danych treningowych i jednocześnie pomaga w unikaniu zbytniego dopasowania.
W tradycyjnej regresji liniowej dąży się do minimalizacji sumy kwadratów różnic między przewidywanymi wartościami a rzeczywistymi wartościami. Ridge Regression dodaje do tego celu dodatkowy składnik, który jest proporcjonalny do kwadratu normy L2 współczynników regresji. Kluczowym parametrem dla regresji ridge jest parametr alfa wyznaczający to jak wysoka będzie kara za złożoność. Im większa wartość alpha, tym większa kara za złożoność, co prowadzi do bardziej ograniczonych wartości wag. To ograniczenie wartości wag ma na celu zmniejszenie wpływu poszczególnych cech na model, zapobieganie zbytniemu dopasowaniu i poprawę ogólnej zdolności do generalizacji na nowych danych.

Dodanie regularyzacji L2 pomaga w redukcji przeuczenia (overfittingu) i poprawie stabilności modelu, szczególnie gdy mamy do czynienia z dużą liczbą cech lub kiedy cechy są silnie skorelowane. Regularyzacja L2 działa poprzez równoczesne minimalizowanie błędu dopasowania danych treningowych oraz ograniczanie wartości wag, co pozwala na uzyskanie bardziej wyważonego modelu.

<Ridge> - odpowiedni podpis


Zastosowanie Ridge Regression jako modelu przewidującego ceny mieszkań.

<Ridge2>  - odpowiedni podpis

Parametry:

Parametr "tol" w modelu Ridge Regression jest wartością progową, która kontroluje warunek zbieżności algorytmu optymalizacji podczas uczenia modelu. Im mniejsza wartość tol, tym bardziej precyzyjne jest kryterium zbieżności, ale wymaga to więcej iteracji. Warto dostosować tol, aby znaleźć odpowiedni kompromis między czasem uczenia a precyzją wyników.

Parametr "alfa" w Ridge Regression kontroluje siłę regularyzacji, czyli wpływ kary za złożoność modelu. Większa wartość alfa prowadzi do większej kary i bardziej ograniczonych wag, co pomaga w zapobieganiu zbytniemu dopasowaniu. Optymalne dobranie wartości alfa jest ważne dla zachowania równowagi między dopasowaniem a regularyzacją.

Wyniki:

Wybrane zostały następujące parametry: 'alpha': 10, 'random_state': 101, 'tol': 1e-05. Wysoki poziom parametru alfa, może świadczyć o sporej liczbie zmiennych nie wnoszących zbyt wiele do predykcji ceny mieszkańa. Dla przypomnienia zbiór posiada ponad cztery tysiące zmiennych.

Wynik jaki uzyskał model Ridge okazał się zaskakująco dobry ponieważ R2 Score wyniósł niespełna 0.89 co przełożyło się między innymi na średni błąd poniżej 8.5%. Różnica pomiędzy modelami Linear Regression, a Ridge również może świadczyć, że ograniczenie złożoności modelu pozytywnie wpyłwa na wynik. Co potwierdza hipoteze, że spora część zmiennych ze zbioru danych jest niezbyt użyteczna. Wartym odnotwania jest fakt, że model dobrze radzi sobie z przewidywaniem ceny mieszkań z dowolnej półki cenowej co prezentuje wykres Predukcje vs. właściwe ceny domów.

KNN Regression

<KNN>  - odpowiedni podpis

Parametry:

Parametr "n_neighbors" w KNN Regressor służy do określenia liczby sąsiadów branych pod uwagę podczas prognozowania wartości docelowych dla nowych obserwacji. Jest to jeden z kluczowych parametrów w algorytmie k-najbliższych sąsiadów (KNN), gdzie obiekt jest przewidywany na podstawie podobieństwa do najbliższych sąsiadów w zbiorze treningowym. Wybór optymalnej wartości n_neighbors może mieć wpływ na wydajność i dokładność modelu KNN, zbyt mała wartość może prowadzić do nadmiernego dopasowania, podczas gdy zbyt duża może prowadzić do niedostatecznego dopasowania.

Parametr 'weights' w KNN Regressor służy do określenia sposobu wagowania sąsiadów podczas prognozowania wartości docelowych dla nowych obserwacji. Istnieją dwie opcje: 'uniform' i 'distance'. Dla 'uniform', wszyscy sąsiedzi mają taką samą wagę, podczas gdy dla 'distance', wagi są odwrotnie proporcjonalne do odległości od nowej obserwacji. Wybór odpowiedniego sposobu wagowania zależy od charakteru danych i problemu, gdzie 'uniform' może być stosowane, gdy wszystkie punkty są równie ważne, a 'distance' może dawać lepsze wyniki, jeśli bliżsi sąsiedzi mają większy wpływ na prognozowanie.

Parametr 'metric' w KNN Regressor służy do określenia metryki używanej do obliczania odległości między obserwacjami w algorytmie k-najbliższych sąsiadów (KNN). Domyślnie wartość tego parametru to 'euclidean', co oznacza obliczanie odległości Euklidesowej. Jednak można również wybrać inne metryki, takie jak 'manhattan' (odległość Manhattan), 'minkowski' (ogólna metryka Minkowskiego) czy 'chebyshev' (odległość Czebyszewa), w zależności od charakterystyki danych i potrzeb problemu. Wybór odpowiedniej metryki ma istotny wpływ na dokładność i efektywność modelu KNN, ponieważ różne metryki mogą lepiej odzwierciedlać specyfikę danych i strukturę przestrzeni.

Wyniki:

Wybrane zostały następujące parametry: 'algorithm': 'auto', 'metric': 'cityblock', 'n_neighbors': 9, 'weights': 'distance'.

Wynik modelu KNN nie wypadł tak dobrze jak w przypadku Ridge, metryki takie jak R2 Score oraz średni błąd są znacząco gorsze niż w przypadku wczesniej opisanego modelu liniowego. Poziom błędu na poziomie przewyższającym 14% jest zdecydowanie za wysoki, aby model ten mógł być użyty w celu analizy danych dotyczących ceny mieszkań. 


DecisionTreeRegressor

<Tree>  - odpowiedni podpis

Parametry:

Parametr 'min_impurity_decrease' w Decision Tree Regressor służy do kontrolowania minimalnego spadku impurity (czystości) w węźle, który jest wymagany do kontynuacji podziału. Wartość tego parametru określa minimalną różnicę impurity, która musi być osiągnięta w wyniku podziału węzła. Jeśli spadek impurity jest mniejszy niż wartość 'min_impurity_decrease', podział w tym węźle nie zostanie wykonany. Parametr ten jest używany do regularyzacji modelu i zapobiegania nadmiernemu dopasowaniu. Wybór optymalnej wartości 'min_impurity_decrease' zależy od charakteru danych i pożądanego poziomu regularyzacji, gdzie większa wartość prowadzi do prostszych drzew i ogranicza podziały o niewielkim spadku impurity.

########################################################################################################################################################################################################

Parametr ccp_alpha (czyli Cost Complexity Pruning alpha) to parametr, który wpływa na proces przycinania drzewa decyzyjnego w algorytmie regresji drzewa decyzyjnego z ograniczeniami. Przycinanie drzewa decyzyjnego polega na usuwaniu nieistotnych węzłów z drzewa, aby zmniejszyć jego złożoność i zapobiec nadmiernemu dopasowaniu (overfitting).

Parametr criterion to parametr, który określa kryterium podziału węzłów w drzewie decyzyjnym. Wyróżniamy mse ora friedman_mse, który jest zmodyfikowaną wersją mse.

Wyniki:

Wybrane zostały następujące parametry:  {'ccp_alpha': 0.3, 'criterion': 'absolute_error', 'min_impurity_decrease': 0.0001, 'random_state': 101}.

Wyniki modelu pojedynczego Drzewa Decyzyjnego tak jak można się było spodziewać nie okazały się zbyt zadawalające, model ten uzyskał wyższy poziom błędów MAE oraz RMSE a co za tym idzie jego R2 Score rówanież był zdecydowanie wyższy od poprzedników. Nie mniej jednak spodziewaliśmy się podobnych wyników, rozpoczynając tą analize zdecydowaliśmy wytrenować oraz sprawdzić najlepsze do naszego zbioru danych hyperparametry dla drzewa decyzyjnego głównie dlatego że chcemy to drzewo decyzyjne wykorzystać w następnych modelach. Kolejne trzy modele będą modelami opartymi na drzewach decyzyjnych, a w jendym z nich bezpośrednio wykorzystamy drzewo ze zdefiniowanymi parametrami powyżej.


RandomForestRegressor
<RandomForest1> - odpowiedni opis


Parametry:

bootstrap - parametr binarny (True/False), określający, czy w procesie budowy każdego drzewa decyzyjnego należy losować próbkę danych z powtórzeniami (zastąpieniami) czy bez powtórzeń (bez zastąpień). W przypadku, gdy bootstrap=True, drzewo będzie budowane na podstawie losowego podzbioru próbek, co zwiększa zróżnicowanie drzew i pomaga w uniknięciu przeuczenia.

ccp_alpha - parametr, który określa minimalną wielkość kosztu cięcia (ang. cost complexity pruning), który musi zostać osiągnięty, aby węzeł był przycinany. Im wyższa wartość ccp_alpha, tym bardziej agresywnie dokonywane jest przycinanie drzewa, co może prowadzić do uproszczenia modelu i zmniejszenia jego skłonności do przeuczenia.

n_estimators - liczba drzew decyzyjnych w lesie losowym. Im wyższa wartość parametru, tym bardziej skomplikowany będzie model i tym większe prawdopodobieństwo uzyskania dokładniejszych wyników, ale zwiększy się też czas trenowania i predykcji. Z drugiej strony, zbyt mała wartość n_estimators może prowadzić do niedouczenia modelu.

Wyniki:

Wybrane zostały następujące parametry:{'bootstrap': True, 'ccp_alpha': 0.02, 'n_estimators': 400, 'random_state':101}

W przypadku RandomForest wyniki okazały się znacznie lepsze niż w przypadku pojedynczego drzewa. Powodem tego jest fakt, że dane na których operujemy są wysoce złozone nawet w pierwotnej formie posiadały ponad 70 kolumn, gdzie po zastosowaniu OneHotEncoding ta liczba wzrosła do 4000. Z tego powodu modele takie jak pojedyncze drzewo decyzyjne nie radzą sobie tak dobrze jak ich bardziej złożone odpowiedniki.


AdaBoost

W tym modelu bezpośrednio użyjemy wcześniej zdefiniowanego drzewa decyzyjnego z poprzedniego rozdziału.
<AdaBoost1>

Parametry:
W przypadku AdaBoost nie było potrzeby definiować takiej ilości hyperparametrów jak w przypadku poprzenich modeli, głównie dlatego że Adaptive Boost wykorzystuje wcześniej zdefiniowane (pod kątem hyperparametrów) drzewo decyzyjne. Dlatego też nie używaliśmy w tym przypadku GridSearchCV, a jedyne parametry jakie zdefiniowaliśmy, dotyczył:
n_estimators - ilości drzew wykorzystywanych przez model.
base_estimators - definicja jakie ma być to drzewo, zdecydowaliśmy się na użycie drzewa zdefiniowanego wcześniej.
learning_Rate - współczynnik określający, jak bardzo każde nowe drzewo decyzyjne będzie próbowało poprawić błędy modelu w poprzednich iteracjach.

<AdaBoost2>

Wyniki

AdaBoost osiągnał wynik zbliżony do Randomforest nieznacznie go przebijając, wartym jednak odnotowania jest fakt, że potrzebował na to kilkukortnie więcej czasu od swojego poprzednika na sam trening.

Gradient Boost

<GradientBoost1>

Parametry:

n_estimators: liczba drzew decyzyjnych, które zostaną zbudowane przez algorytm Gradient Boost. Im większa wartość parametru, tym bardziej złożony będzie model, ale jednocześnie wzrośnie też czas trenowania i predykcji.

learning_rate: współczynnik określający, jak bardzo każde nowe drzewo decyzyjne będzie próbowało poprawić błędy modelu w poprzednich iteracjach. Im wyższa wartość parametru, tym większe będą korekty i tym bardziej skomplikowany będzie model.

min_impurity_decrease: minimalna zmiana impurity, która musi zostać osiągnięta, aby węzeł drzewa decyzyjnego był podzielony. Im wyższa wartość parametru, tym bardziej agresywnie dokonywane jest przycinanie drzewa, co może prowadzić do uproszczenia modelu i zmniejszenia jego skłonności do przeuczenia.

tol: wartość progowa określająca minimalną wartość zmiany funkcji kosztu między kolejnymi iteracjami, która jest wymagana, aby algorytm zakończył iteracje. Im mniejsza wartość parametru, tym więcej iteracji jest potrzebnych, aby algorytm zakończył pracę.

max_depth: maksymalna głębokość drzewa decyzyjnego. Im większa wartość parametru, tym bardziej skomplikowany i bardziej dopasowany do danych będzie model, ale jednocześnie będzie bardziej skłonny do przeuczenia.

ccp_alpha: parametr określający minimalną wielkość kosztu cięcia, która musi zostać osiągnięta, aby węzeł drzewa decyzyjnego był przycinany. Im wyższa wartość parametru, tym bardziej agresywnie dokonywane jest przycinanie drzewa, co może prowadzić do uproszczenia modelu i zmniejszenia jego skłonności do przeuczenia.

Wyniki 

Wybrane zostały następujące parametry: {n_estimators=250, min_impurity_decrease=0.0001,tol=0.00001,learning_rate=0.125, max_depth=5, ccp_alpha=0.01}

GradientBoost, tak jak dwa poprze wykorzystujący wiele drzew poradził sobie znakomicie z przewidywaniem ceny domów. Wynik, w którym średni błąd osiąga poziom poniżej 8 % jest zdecydowanie zadowalający. Można powiedzieć, że model ten jest bardzo podobny do RandomForest, ponieważ tak samo wykorzystuje wiele drzew decyzyjnych. Różnica jednak pomiędzy nimi jest diametralna. GradientBoost w przeciwieństwie do RandomForest nie traktuje każdego nowego drzewa jako osobny byt, kolejne drzewa w tym modelu "uczą" się na błędach poprzedników. 
########################################################################################################################################################################################################















